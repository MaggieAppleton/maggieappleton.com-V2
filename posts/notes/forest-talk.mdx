---
title: "Talk: The Expanding Dark Forest and Generative AI"
description: "Proving you're a human on a web flooded with generative AI content"
type: "note"
topics: ["Artificial Intelligence", "Anthropology", "Language Models"]
updated: "2023-04-27"
startDate: "2023-04-27"
growthStage: "budding"
---

<Spacer size="small" />

Slides and notes from my talk at [Causal Islands]() in Toronto, April 25-27th, 2023

<BasicImage width="1200px" src="/images/posts/forest-talk/dft_1.jpeg" />

<TalkSlide imgSrc="/images/posts/forest-talk/dft_2.jpeg">

This is going to be about writing on the web, trust, and human relationships (small fish)

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_3.jpeg">

And inevitably, AI. Sorry.

A small footnote: this talk up to date as of about 2 weeks ago which means everything I say about the current state of AI is probably completely irrelevant by now.

I have essentially gathered some thoughts that relate to a moment in time that has just whooshed past us.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_4.jpeg">

First, some context. I’m Maggie and I want to lay out all my biases up front.

I’m a designer at an AI research lab called Ought. My job involves creating tools that use language models to augment and expand human reasoning.

In practice, these tools are primarily aimed at academics and large organizations such as governments and non-profits, helping them to understand scientific literature and make decisions.

Secondly, I’m what we call “very online”. I live on Twitter and write a lot online. I hang out with people who do the same, and we write blog posts and essays to each other while researching, almost like 18th-century men of letters! This has led to lots of friends and collaborators and wonderful jobs.

Being a sincere human on the web has been an overwhelmingly positive experience for me, and I want others to have that same experience.

Lastly, before tech, I studied cultural anthropology. This gives me useful perspectives, frameworks, and tools to think about culture and social behaviour on the web.

</TalkSlide>


<TalkSlide imgSrc="/images/posts/forest-talk/dft_6.jpeg">

I’ll first discuss the dark forest theory of the web, then talk about the state of generative AI.

We'll then consider if we have a problem here. I’ll lay out hypothetical problems and examine if they’re valid.

Then we'll cover possible futures and how to deal with those hypothetical problems.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_8.jpeg">

To explain the dark forest theory of the web, I first need to explain the dark forest theory of the universe. This theory attempts to explain why we haven’t yet discovered intelligent life in the universe.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_9.jpeg">

Here we are - the pale blue dot

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_10.jpeg">

As the only known intelligent life in the universe, we’ve been beaming out messages for 60 years in an attempt to find others.

But we haven’t heard anything back yet.

Dark forest theory suggests that the universe is like a dark forest at night - a place that appears quiet and lifeless because if you make noise...

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_11.jpeg">

...the predators will come eat you.

This theory proposes that all other intelligent civilizations were either killed or learned to shut up. We don’t yet know which category we fall into.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_13.jpeg">

The web version builds off that concept

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_14.jpeg">

This is a theory proposed by Yancey Striker in 2019 in the article [XXX]()

Yancey describes some trends and shifts around what it feels like to be in the public spaces of the web.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_15.jpeg">

Yancey pointed out a two main “vibes”. First that the web can often feel lifeless, automated, and devoid of humanns.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_16.jpeg">

Here we are on the web

And we're naively writing a bunch of sincere and authentic accounts of our lives and thoughts and experiences. Trying to find other intelligent people who share our beliefs and interests

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_17.jpeg">

But feels like we’re surrounded by content that doesn’t feel authentic and human.
Lots of this content is authored by bots, marketing automation, and growth hackers pumping out generic clickbait with ulterior motives.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_18.jpeg">

We have all seen this stuff.

Low-quality listicles...

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_19.jpeg">

...productivity rubbish...

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_20.jpeg">

...insincere templated crap...

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_21.jpeg">

...growth hacking advice...

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_22.jpeg">

...banal motivational quotes...

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_23.jpeg">


</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_24.jpeg">


...and dramatic clickbait.

This stuff may as well be automated. It's rarely trying to communicate sincere and original thoughts and ideas to other humans. Mostly trying to get you to click and rack up views.

The overwhelming flood of this low-quality content makes us retreat away from public spaces of the web. It's too costly to spend our time and energy wading through it.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_25.jpeg">

The second vibe of the dark forest web is lots of unnecessarily antagonistic behaviour, at scale.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_26.jpeg">

When we put out signals trying to connect with other humans, we risk becoming a target. 

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_27.jpeg">

Specifically, the twitter mob might come to eat us.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_29.jpeg">

There’s a term on Twitter called getting “main charactered”.

Every day there is one main character on Twitter and your goal is to not be that character. They get piled on by everyone for saying the wrong thing.
Sometimes they deserve it, but it's often quite arbitrary. I’ve had close friends get main charactered for frankly very banal and minor things

A good example of this is garden lady from October.

Some of you may have seen this. This woman tweeted this lovely, sweet message about loving her husband and spending hours every morning talking to him in the garden over coffee.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_30.jpeg">

The replies were priceless

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_31.jpeg">



</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_32.jpeg">



</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_33.jpeg">

TikTok captured this vibe well – "I don't really care if something good happened to you. It should have happened to me instead."

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_34.jpeg">

In his book “So You’ve Been Publicly Shamed,” Jon Ronson explores how cancelling and publicly shaming others has become a common practice on social media.

This phenomenon has real material consequences for people, causing them to lose their jobs, become alienated from their communities, and suffer emotional trauma. 

Many people choose not to engage on the public web because it's become a sincerely dangerous place to express your true thoughts.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_35.jpeg">

It’s difficult to find people who are being sincere, seeking coherence, and building collective knowledge in public.

While I understand that not everyone wants to engage in these activities on the web all the time, some people just want to dance on TikTok, and that’s fine!

However, I’m interested in enabling productive discourse and community building on at least some parts of the web. I imagine that others here feel the same way. 

Rather than being a primarily threatening and inhuman place where nothing is taken in good faith.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_36.jpeg">

So, how do we cope with this?

While wandering around the dark forest of Facebook and Linked in and Twitter, most of us realised we need to go somewhere safer.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_37.jpeg">

We end up retreating to what’s been called the “cozy web.”

This term was coined by Venkat Rao in [XXX]() in direct response to the dark forest theory of the web. Venkat point out that we’ve all started going underground, as if were.

We move to semi-private spaces like newsletters and personal websites where we’re less at risk of attack.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_38.jpeg">

However, even personal websites and newsletters can sometimes be too public, so we retreat further into gatekept private chat apps like Slack, Discord, and WhatsApp.

These apps allow us to spend most of our time in real human relationships and express our ideas, with things we say taken in good faith and opportunities for real discussions.

The problem is that none of this is indexed or searchable, and we’re hiding collective knowledge in private databases that we don’t own. Good luck searching on Discord!

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_39.jpeg">

My current theory is that the dark forest parts of the web are about to expand.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_40.jpeg">

We now have what’s being called generative AI

These are machine learning models that can generate content that before this point in history, only humans could make. This includes text, images, videos, and audio.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_41.jpeg">

Here are some the popular models for each media type
I’m sure you’ve all heard of some of these.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_42.jpeg">

Obviously, this is ChatGPT. We've all seen thousands of screenshots of this.

It's a large language model that can generate huge volumes of human-like text in seconds. 

I’m going to assume a fair amount of knowledge about language models in this crowd.

The key points to know are:

- It's outputs are generally indistinguishable from human-made text, roughly at a high school essay level. We should acknowledge that these outputs are astonishingly good. I'll get to the flaws and weaknesses of language models later.
- They're trained on a huge volume of text scraped primarily from the English-speaking web.
- All language models do is predict the next word in a sequence, which may sound simple but leads to all kinds of complex and potentially useful behaviour.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_43.jpeg">

We can also generate images. These are outputs from Midjourney.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_44.jpeg">

We can also do videos. This is a demo from [Synesthesia]().

Obviously, still slightly uncanny valley at this stage.

Not going to focus on video and image outputs for this talk.
Just going to focus on language models.

Deepfakes are a problem, but I’m all full up on problems.
Someone else is going to have to do that talk.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_45.jpeg">

By now language models have been turned into lots of easy-to-use products
No technical skills needed

These are some popular copywriting apps out in the world: Jasper, Copy.ai, Moonbeam

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_46.jpeg">

Most of these are article generator tools. They tend to work like this.

You type in what you want to write about. I’ve said carbon credits here and why they’re ineffective. Which I know nothing about.

So I’ll have this model write an article for me.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_47.jpeg">

And then it churns out 700 words on it.
This is now ready for me to publish.

Which if I’m someone lobbying against carbon credits is handy.

I can generate 100 of these, optimise them for Google search terms, and shove them on the web.

A hard day’s advocacy done!

The quality and truthfulness of this is clearly questionable, but we’ll get to the problems with it later.

The point is this is very easy to do.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_48.jpeg">

This isn't limited to blog posts and articles.
Any text that can be generated will.

They give you an array of convenient formats.
Like presenting yourself on a dating site and wedding vows.
Or “sharing tips and knowledge”. Though clearly not based off anything you’ve actually learned.

There’s every manifestation of this...

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_49.jpeg">

...Tweet generators...

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_50.jpeg">

...Linked In post generators...

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_51.jpeg">

... turn YouTube videos into tweets and vice versa.

You're able to reuse content quite easily. This is all a marketer's dream!

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_52.jpeg">

Most of the tools and examples I’ve shown have a simple architecture.

They’re made by feeding a single input, or prompt, into the big black mystery box of a language model. (We call them black boxes because we can’t really see how they reason or produce answers. It's a mystery to everyone, including their creators.)

And we get a single output – an image, some text, or an article.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_53.jpeg">

We can scale that up to many outputs.

Most companies that make language models have an API you can hit. So we can ask for 1,000 or 100,000 articles.

But we’re still limited in how sophisticated we can get with these outputs.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_54.jpeg">

Recently, we have seen more sophisticated methods of prompting language models, such as "prompt chaining" or composition.

Ought has been researching this for a few years, and libraries like LangChain have become popular in the last few months.

This approach solves many flaws in language models, such as a lack of knowledge of recent events, inaccuracy, difficulty with mathematics, lack of longterm memory, and inability to interact with the rest of our digital systems.

Prompt chaining is a way of setting up a language model to act in a loop with external tools.

It starts with an input goal, and then the model observes and reflects on what it knows and its goals, deciding on a course of action by picking from a set of available tools to solve the problem, such as searching the web, writing and running code, querying a database, using a calculator, hitting an API, connecting to Zapier or IFTTT, etc.

After each action, the model reflects on what it learned and then picks another action, continuing until it arrives at the final output.

This gives us much more sophisticated answers than a single language model call, making them more accurate and able to do more complex tasks.

This mimics a very basic version of how humans reason. It's similar to the OODA loop (Observe, Orient, Decide, Act).

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_55.jpeg">

Recently, people have taken this idea further and developing new ways to create “generative agents”.

Just over two weeks ago, a paper came out outlining an experiment where they made a sim-like game (as in, [The Sims]()) filled with little people, each controlled by a language-model agent. 

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_56.jpeg">

The tiny sim language models had some key features, such as a long-term memory database they could read and write to, the ability to reflect on their experiences, plan what to do next, and interact with other sim agents in the game.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_57.jpeg">

And this architecture produced very compelling and believable human behaviours.

The agents would perform everyday tasks such as cooking breakfast, stopping if something is burning, chatting to one another, forming opinions, and reflecting on their day.

Additionally, these agents have also been shown to exhibit more emergent social behaviours, such as planning and attending a Valentine's Day party and asking each other out on dates.

There's a new library called [AgentGPT]() that's making it easier to build these kind of agents. We're now able to easily spin up similar agents for the web.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_58.jpeg">

I think we’re about to enter a stage of sharing the web with non-human agents that are very different to our current bots – they have a lot more data on how behave like realistic humans and are rapidly going to get more and more capable.

Soon we won’t be able to tell the difference between generative agents and real humans on the web.

Sharing the web with agents isn’t inherently bad and could have good use cases such as automated moderators and search assistants, but it’s going to get complicated.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_59.jpeg">

Now, why is this a problem?

I’m only going to focus on how this will be a problem for humans relationships and information over the web.

Anything else – like how we might all end up unemployed or dead soon – is beyond my pay grade.

</TalkSlide>


<TalkSlide imgSrc="/images/posts/forest-talk/dft_60.jpeg">

The cost of creating and publishing content to the web has just dropped to almost zero. Humans are expensive and slow at making content, needing time to research, read, think, and clumsily string words together, as well as taking breaks, eating, sleeping, and showering.

Generative models, on the other hand, write much faster, don't need time off, and don't get bored. ChatGPT currently costs a fraction of a cent ($0.002) to generate 1000 tokens (words), meaning that it would cost only two cents to generate 100 articles of 1000 words. If we used a more sophisticated architecture like prompt chaining the cost would certainly be higher, but still affordable.

Given that these creations are cheap, easy to use, fast, and can produce a nearly infinite amount of content, the cost of creating and publishing content to the web has become almost negligible.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_61.jpeg">

I think we’re about to drown in a sea of informational garbage.

We’re going to be absolutely swamped by masses of mediocre content.

Every marketer, SEO strategist, and optimiser bro is going to have a field day
filling Twitter and Facebook and Linked In and Google search results
with masses of keyword-stuffed, optimised, generated crap

This explosion of noise will make it difficult to find good-quality content and hear any signal.

While we already have tools to deal with spam and filter low-quality content, I think this new, more sophisticated type will leak through. I expect it will take a few years to get our content moderation, filtering, and defence systems to catch up.

Meta note: This image was made in Midjourney. It's the only AI-generated image I’m using in this talk. I mostly wanted to show that AI can do hands now – progress!

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_62.jpeg">

We can tell this is already happening because spammers and scammers are lazy as fuck.

This recent [verge article]() pointed out that the phrase “as an AI language model” is showing up in all kinds of places: Amazon reviews, Yelp reviews, Tweets, and LinkedIn posts.

This is a common phrase that shows up in ChatGPT outputs.

The fact spammers couldn’t even be bothered to remove this obvious giveaway from their outputs shows the level of care and detail they’ll put into future work.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_63.jpeg">

Let’s look at some hypothetical scenarios of how this might unfold.

This is Nigel. He’s written a book on ‘Why Nepotism is Great’ and he wants to be a bookfluencer. We're going to give him the benefit of the doubt and assume he's actually written this book and not prompted it into existence.

So he spins up an agent

And tells it to promote the book (not so different to a traditional book agent!)

And then gives it access to all his social media accounts via APIs or something like Zapier.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_64.jpeg">

The agent take a moment to strategise. And then gets to work.

It generates and schedules a steady stream of tweets, LinkedIn and Facebook posts based on the book content, writes and schedules a newsletter every week for 6 months, sets up a Medium account and republishes those as articles, creates a set of addictive TikTok videos, a 24-part series for YouTube, generates a bunch of podcast episodes that use Nigel’s voice, and finds other people writing about nepotism and starts replying to everything they publish on Twitter, LinkedIn, etc.

This is not that different to what Nigel could do, but the agent doesn’t make tons of content so as not to set off any red flags on Nigel’s accounts. Without an agent, 99% of Nigles wouldn’t have the time, energy and motivation to do this, even if they’ve written a book, and certainly can’t do this volume and consistency of output.

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_65.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_66.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_67.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_68.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_69.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_70.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_71.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_72.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_73.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_74.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_75.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_76.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_77.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_78.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_79.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_80.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_81.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_82.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_83.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_84.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_85.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_86.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_87.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_88.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_89.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_90.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_91.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_92.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_93.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_94.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_95.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_96.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_97.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_98.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_99.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_100.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_101.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_102.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_103.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_104.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_105.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_106.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_107.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_108.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_109.jpeg">

Peg

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_110.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_111.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_112.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_113.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_114.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_115.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_116.jpeg">

Notes

</TalkSlide>

<TalkSlide imgSrc="/images/posts/forest-talk/dft_117.jpeg">

End

</TalkSlide>