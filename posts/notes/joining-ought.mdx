---
title: "Joining Ought"
description: "A new role at an AI research lab working on tools for open-ended reasoning"
startDate: "2022-07-15"
updated: "2022-07-15"
type: "note"
topics: [ "Machine Learning", "Design","Artificial Intelligence","Tools for Thought"]
growthStage: "evergreen"
aliases: ["joined Elicit"]
---

<IntroParagraph>

Starting at the end of August, I'm joining [Ought](https://ought.org/) as their first product designer. Ought is a non-profit research lab. They're exploring how [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing) (NLP) and [machine learning](https://en.wikipedia.org/wiki/Machine_learning) (ML) tools can improve researcher workflows. Specifically, how these new tools can help people with open-ended reasoning ‚Äì thinking through problems that don't have simple, clear-cut answers.

</IntroParagraph>

Their main product at the moment is [Elicit](https://elicit.org/) - an AI assistant for academic and professional researchers. It uses NLP to find research papers, synthesise them, and extract research questions, evidence, and arguments from them. They're currently focused on helping people do literature reviews. But [the plan](https://docs.google.com/document/d/1D75EsWJdobyxJN7fxygybBIlBtrbgRXEcrYdhcmWppE/edit) is to expand Elicit's capacities to help with the whole research process.

<ScrollingImages
	title="Searching for answers to a research question in the current version of Elicit (July 2022)"
	data={[
		{
			src: "https://res.cloudinary.com/dxj9qr5gj/image/upload/c_scale,f_auto,q_auto:best,w_1600/v1657716620/maggieappleton.com/notes/joining-ought/elicit1_sdg5nc.jpg",
			alt: "the main search screen of elicit",
		},
		{
			src: "https://res.cloudinary.com/dxj9qr5gj/image/upload/c_scale,f_auto,q_auto:best,w_1600/v1657716621/maggieappleton.com/notes/joining-ought/elicit4_xqmzqt.jpg",
			alt: "the results screen of elicit",
		},
		{
			src: "https://res.cloudinary.com/dxj9qr5gj/image/upload/c_scale,f_auto,q_auto:best,w_1600/v1657716621/maggieappleton.com/notes/joining-ought/elicit5_dd7ja8.jpg",
			alt: "the suggested questions screen of elicit",
		},
		{
			src: "https://res.cloudinary.com/dxj9qr5gj/image/upload/c_scale,f_auto,q_auto:best,w_1600/v1657716621/maggieappleton.com/notes/joining-ought/elicit3_wooe5j.jpg",
			alt: "the detail view of a single paper in elicit",
		},
	]}
/>

I got access to the alpha version of Elicit in July of 2021 and was immediately hooked. Even though I‚Äôm an amateur researcher<Footnote idName={1}>Meaning I do it as part of my job as a designer and writer, but in a rather a naive way compared to anyone writing a PhD.</Footnote>, I still spend a good chunk of time hunting down and reading academic publications.

I found the results were on par with what Google Scholar or Semantic Scholar would turn up. But the Elicit results show _why_ it returns certain papers ‚Äì each paper has a [GPT-3](https://openai.com/api/) generated summary that tries to answer the original question. It's a small difference, but a huge help when you're drowning in PDFs and trying to quickly find the right ones to read.<Footnote idName={2}>As with all things generated by automated systems, these results aren't meant to be swallowed whole without critical thought and due diligence. They're helpful guideposts that humans still need to double-check and validate.</Footnote>

I'll stop with the sales pitch now. <span role="img">üòâ</span> Elicit is free and you can [try it out](https://elicit.org) if you want to see for yourself.

I'm also excited to explore what's possible beyond summarising papers. In [[Programmable Notes]] I discussed what it might look like to add AI agents into personal notes and knowledge management systems. Many of Elicit's secondary workflows point in that direction. You can [generate](https://ide.elicit.org/run/JqRpiAJMnNacB7wvq) research questions, [rephrase](https://ide.elicit.org/run/9uFGfJBhFbPRaaQ2z) ideas, or explore [chains of reasoning](https://ide.elicit.org/run/Are3MaP2XsRJFuKLT).

Suffice to say, there's a lot to dive into. Language models and neural networks are all relatively new. GPT-3 is barely 2 years old. We don't have many established design patterns or canonical interfaces for this stuff yet.

I am also new to this space. I haven't worked on any ML and NLP projects yet so I have a fat reading list to work through. Like most people, I've heard plenty of cultural narratives around the nebulous concept of ‚ÄúAI‚Äù. Anthropologists like [Nick Seaver](https://nickseaver.net/writing), [danah boyd](https://www.danah.org/), and [Genevieve Bell](https://en.wikipedia.org/wiki/Genevieve_Bell) have given me a good critical lens on the space. But I've never looked into the details of how these systems work.

3Blue1Brown's series on [neural networks](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) gave me a beautiful, visual synopsis of what happens inside a neural net. [Human Compatible](https://en.wikipedia.org/wiki/Human_Compatible) by Stewart Russell gave me good historical and cultural context. [Distill](https://distill.pub/)'s articles gave me delightfully interactive deep dives into particular topics. It's wild what people put on the internet for free.

I'm leaving behind the team at [HASH](https://hash.ai) and the [Block Protocol](https://blockprotocol.org) project to take on this new role. I still support what they're working on, and I know they'll find another great design lead to take over. I'm still bullish on schema-based knowledge management, block-based editors, and interfaces that enable end-user programming.

Perhaps these threads will all tie back together at some point. I wouldn't be surprised.
